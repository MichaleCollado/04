{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84b817ad-3f72-402d-99e2-188ae86dd03a",
   "metadata": {},
   "source": [
    "# 03-SQL-Consultas-Avanzadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9794619c-9f3f-4cab-8404-44bfca3fc457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b8ac227-d375-4b72-88dc-ab3d636521fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conerctar a mi SQLserver\n",
    "driver = \"ODBC Driver 17 for SQL Server\"\n",
    "server = r\"DESKTOP-GB9FFBV\"\n",
    "database = \"BD_SQL_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15e746f5-a46b-40cd-a8e7-9c229f18145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear motor de conexión\n",
    "connection_string = f\"mssql+pyodbc://@{server}/{database}?driver={driver}\"\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd389526-6955-43b1-9aed-542caa707eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id_producto nombre_producto  anio  mes  variacion\n",
      "0               1      Producto 1  2023    7        NaN\n",
      "1               1      Producto 1  2023    1  35.463885\n",
      "2               1      Producto 1  2023   10  -0.499514\n",
      "3               1      Producto 1  2023    4  29.962401\n",
      "4               1      Producto 1  2023    5 -25.986011\n",
      "...           ...             ...   ...  ...        ...\n",
      "1235           40     Producto 40  2025    1   4.700500\n",
      "1236           40     Producto 40  2025    6  -3.121225\n",
      "1237           40     Producto 40  2025    4  -7.262485\n",
      "1238           40     Producto 40  2025    3  45.922950\n",
      "1239           40     Producto 40  2025    2  17.773857\n",
      "\n",
      "[1240 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 1. Calcular la variación porcentual de ventas mes a mes por producto.\n",
    "# -------------------------------\n",
    "df1 = pd.read_sql(\"\"\"\n",
    "WITH t1 AS (\n",
    "    SELECT v.id_producto, p.nombre_producto,\n",
    "           DATEPART(year, fecha_venta) AS anio,\n",
    "           DATEPART(month, fecha_venta) AS mes,\n",
    "           SUM(v.precio_unitario * v.cantidad) AS total_venta,\n",
    "           LAG(SUM(v.precio_unitario * v.cantidad),1) OVER (PARTITION BY v.id_producto ORDER BY DATEPART(year, fecha_venta)) AS total_venta_anterior\n",
    "    FROM ventas v INNER JOIN productos p ON v.id_producto = p.id_producto\n",
    "    GROUP BY v.id_producto, p.nombre_producto, DATEPART(year, fecha_venta), DATEPART(month, fecha_venta)\n",
    ")\n",
    "SELECT id_producto, nombre_producto, anio, mes,\n",
    "       (total_venta - total_venta_anterior) / total_venta_anterior * 100 AS variacion\n",
    "FROM t1;\n",
    "\"\"\", engine)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ed649e5-4b70-445c-a0aa-9e48c933bf57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id_cliente       nombre  anio  mes    total_mes  mes_anterior  \\\n",
      "0               1    Cliente 1  2023    1  1056.089981           NaN   \n",
      "1               1    Cliente 1  2023    2  1730.719971   1056.089981   \n",
      "2               1    Cliente 1  2023    3  1694.730011   1730.719971   \n",
      "3               1    Cliente 1  2023    5  2042.939941   1694.730011   \n",
      "4               1    Cliente 1  2023    6   859.749985   2042.939941   \n",
      "...           ...          ...   ...  ...          ...           ...   \n",
      "15457         800  Cliente 800  2024    9   331.510010    552.239990   \n",
      "15458         800  Cliente 800  2024   10   374.620018    331.510010   \n",
      "15459         800  Cliente 800  2025    4   215.039993   1352.609997   \n",
      "15460         800  Cliente 800  2025    5   124.000000    215.039993   \n",
      "15461         800  Cliente 800  2025    6   882.100006    124.000000   \n",
      "\n",
      "       mes_trasanterior  \n",
      "0                   NaN  \n",
      "1                   NaN  \n",
      "2           1056.089981  \n",
      "3           1730.719971  \n",
      "4           1694.730011  \n",
      "...                 ...  \n",
      "15457       3916.349945  \n",
      "15458        552.239990  \n",
      "15459       1230.599976  \n",
      "15460       1352.609997  \n",
      "15461        215.039993  \n",
      "\n",
      "[15462 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 2. Identificar clientes con tres meses consecutivos de crecimiento en compras.\n",
    "# -------------------------------\n",
    "df2 = pd.read_sql(\"\"\"\n",
    "WITH t1 AS (\n",
    "    SELECT v.id_cliente, c.nombre,\n",
    "           DATEPART(year, v.fecha_venta) AS anio,\n",
    "           DATEPART(month, v.fecha_venta) AS mes,\n",
    "           SUM(v.precio_unitario * v.cantidad) AS total_mes,\n",
    "           LAG(SUM(v.precio_unitario * v.cantidad),1) OVER (PARTITION BY v.id_cliente ORDER BY DATEPART(year, v.fecha_venta), DATEPART(month, v.fecha_venta)) AS mes_anterior,\n",
    "           LAG(SUM(v.precio_unitario * v.cantidad),2) OVER (PARTITION BY v.id_cliente ORDER BY DATEPART(year, v.fecha_venta), DATEPART(month, v.fecha_venta)) AS mes_trasanterior\n",
    "    FROM ventas v INNER JOIN clientes c ON v.id_cliente = c.id_cliente\n",
    "    GROUP BY v.id_cliente, c.nombre, DATEPART(year, v.fecha_venta), DATEPART(month, v.fecha_venta)\n",
    "),\n",
    "t2 AS (\n",
    "    SELECT id_cliente, nombre, anio, mes, total_mes, mes_anterior, mes_trasanterior,\n",
    "           CASE WHEN total_mes > mes_anterior AND mes_anterior > mes_trasanterior THEN 1 ELSE 0 END AS MesesCrecimiento\n",
    "    FROM t1\n",
    ")\n",
    "SELECT id_cliente, nombre, anio, mes, total_mes, mes_anterior, mes_trasanterior\n",
    "FROM t2\n",
    "WHERE MesesCrecimiento = 0;\n",
    "\"\"\", engine)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5892928c-3507-4f8f-8788-3abea7e7baaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id_departamento nombre_departamento        media\n",
      "0                 1             Depto 1  5875.004883\n",
      "1                 2             Depto 2  2221.429932\n",
      "2                 3             Depto 3  6011.979980\n",
      "3                 4             Depto 4  3484.520020\n",
      "4                 5             Depto 5  5457.135010\n",
      "5                 6             Depto 6  6882.070068\n",
      "6                 7             Depto 7          NaN\n",
      "7                 8             Depto 8  6868.859863\n",
      "8                 9             Depto 9  4806.419922\n",
      "9                10            Depto 10          NaN\n",
      "10               11            Depto 11  4853.114990\n",
      "11               12            Depto 12  6969.410156\n",
      "12               13            Depto 13  3613.179932\n",
      "13               14            Depto 14          NaN\n",
      "14               15            Depto 15          NaN\n",
      "15               16            Depto 16  7864.180176\n",
      "16               17            Depto 17          NaN\n",
      "17               18            Depto 18          NaN\n",
      "18               19            Depto 19  5796.109863\n",
      "19               20            Depto 20  1715.729980\n",
      "20               21            Depto 21  2320.719971\n",
      "21               22            Depto 22          NaN\n",
      "22               23            Depto 23          NaN\n",
      "23               24            Depto 24          NaN\n",
      "24               25            Depto 25  4280.459961\n",
      "25               26            Depto 26  5745.560059\n",
      "26               27            Depto 27  5383.229980\n",
      "27               28            Depto 28  2636.729980\n",
      "28               29            Depto 29  6624.910156\n",
      "29               30            Depto 30  5161.214844\n",
      "30               31            Depto 31  2976.669922\n",
      "31               32            Depto 32  4297.609985\n",
      "32               33            Depto 33  4255.554932\n",
      "33               34            Depto 34  4718.389893\n",
      "34               35            Depto 35  7162.830078\n",
      "35               36            Depto 36          NaN\n",
      "36               37            Depto 37  2288.479980\n",
      "37               38            Depto 38  6883.620117\n",
      "38               39            Depto 39          NaN\n",
      "39               40            Depto 40  4712.379883\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 3. Calcular la mediana de salarios por departamento.\n",
    "# -------------------------------\n",
    "df3 = pd.read_sql(\"\"\"\n",
    "SELECT DISTINCT d.id_departamento, d.nombre_departamento,\n",
    "       PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY e.salario) OVER (PARTITION BY d.id_departamento) AS media\n",
    "FROM departamentos d LEFT JOIN empleados e ON d.id_departamento = e.id_departamento;\n",
    "\"\"\", engine)\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74d981f2-6eee-40d9-a016-598002ae1fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id_producto nombre_producto         mes    t_mes_base     t_mes_sig  \\\n",
      "0              1      Producto 1  2024-05-01  33388.979761  22072.540009   \n",
      "1              1      Producto 1  2024-11-01  29605.669952  17562.709871   \n",
      "2              1      Producto 1  2025-06-01  16315.829979  15966.879944   \n",
      "3              1      Producto 1  2025-07-01  23002.639740  16315.829979   \n",
      "4              2      Producto 2  2023-03-01  28110.659817  23935.489914   \n",
      "..           ...             ...         ...           ...           ...   \n",
      "189           40     Producto 40  2024-01-01  25260.829891  22062.350224   \n",
      "190           40     Producto 40  2024-04-01  24632.640112  20666.699909   \n",
      "191           40     Producto 40  2024-05-01  25577.830158  24632.640112   \n",
      "192           40     Producto 40  2025-02-01  32559.889736  21087.560078   \n",
      "193           40     Producto 40  2025-06-01  20429.369905  20140.839878   \n",
      "\n",
      "       t_mes_2sig  Cumple  \n",
      "0    16145.449932       1  \n",
      "1    16381.479988       1  \n",
      "2    14950.349930       1  \n",
      "3    15966.879944       1  \n",
      "4    17726.990055       1  \n",
      "..            ...     ...  \n",
      "189  19619.349854       1  \n",
      "190  17070.709976       1  \n",
      "191  20666.699909       1  \n",
      "192  20804.359856       1  \n",
      "193  18945.689999       1  \n",
      "\n",
      "[194 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 4. Mostrar los productos con ventas crecientes en los últimos tres periodos.\n",
    "# -------------------------------\n",
    "df4 = pd.read_sql(\"\"\"\n",
    "WITH t1 AS (\n",
    "    SELECT p.id_producto, p.nombre_producto,\n",
    "           DATETRUNC(month, v.fecha_venta) AS mes,\n",
    "           SUM(v.precio_unitario * v.cantidad) AS t_mes_base,\n",
    "           LAG(SUM(v.precio_unitario * v.cantidad), 1) OVER (PARTITION BY p.id_producto ORDER BY DATETRUNC(month, v.fecha_venta)) AS t_mes_sig,\n",
    "           LAG(SUM(v.precio_unitario * v.cantidad), 2) OVER (PARTITION BY p.id_producto ORDER BY DATETRUNC(month, v.fecha_venta)) AS t_mes_2sig\n",
    "    FROM ventas v INNER JOIN productos p ON v.id_producto = p.id_producto\n",
    "    GROUP BY p.id_producto, p.nombre_producto, DATETRUNC(month, v.fecha_venta)\n",
    "),\n",
    "t2 AS (\n",
    "    SELECT *, CASE WHEN t_mes_base > t_mes_sig AND t_mes_sig > t_mes_2sig THEN 1 ELSE 0 END AS Cumple\n",
    "    FROM t1\n",
    ")\n",
    "SELECT * FROM t2 WHERE Cumple = 1;\n",
    "\"\"\", engine)\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2652e2b2-5c97-4ac1-9a5c-7f97c14d4d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   region  id_vendedor       nombre          total  ranking\n",
      "0  Centro           12  Empleado 12  145772.980022        1\n",
      "1   Norte           24  Empleado 24  138353.859585        1\n",
      "2     Sur           28  Empleado 28  138715.470005        1\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 5. Obtener el top 2 de vendedores por región usando funciones analíticas.\n",
    "# -------------------------------\n",
    "df5 = pd.read_sql(\"\"\"\n",
    "WITH t1 AS (\n",
    "    SELECT v.region, e.id_vendedor, e.nombre,\n",
    "           SUM(v.precio_unitario * cantidad) AS total,\n",
    "           DENSE_RANK() OVER (PARTITION BY v.region ORDER BY SUM(v.precio_unitario * cantidad)) AS ranking\n",
    "    FROM ventas v INNER JOIN empleados e ON v.id_vendedor = e.id_vendedor\n",
    "    GROUP BY v.region, e.id_vendedor, e.nombre\n",
    ")\n",
    "SELECT * FROM t1 WHERE ranking < 2;\n",
    "\"\"\", engine)\n",
    "print(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f731df3-e0ea-46b7-8a86-e9c935e6525d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consulta no ejecutable: faltan columnas históricas de salario para resolver esta pregunta.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 6. Detectar empleados que nunca tuvieron una reducción salarial.\n",
    "# -------------------------------\n",
    "print(\"Consulta no ejecutable: faltan columnas históricas de salario para resolver esta pregunta.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ade3dc5a-fc6f-47db-aba2-f7c1bcb75b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          periodo  id_cliente       nombre        total     acumulado\n",
      "0      2023-01-01           1    Cliente 1  1056.089981   1056.089981\n",
      "1      2023-02-01           1    Cliente 1  1730.719971   2786.809952\n",
      "2      2023-03-01           1    Cliente 1  1694.730011   4481.539963\n",
      "3      2023-05-01           1    Cliente 1  2042.939941   6524.479904\n",
      "4      2023-06-01           1    Cliente 1   859.749985   7384.229889\n",
      "...           ...         ...          ...          ...           ...\n",
      "18196  2025-02-01         800  Cliente 800  1352.609997  23423.579983\n",
      "18197  2025-04-01         800  Cliente 800   215.039993  23638.619976\n",
      "18198  2025-05-01         800  Cliente 800   124.000000  23762.619976\n",
      "18199  2025-06-01         800  Cliente 800   882.100006  24644.719982\n",
      "18200  2025-07-01         800  Cliente 800  1250.560059  25895.280041\n",
      "\n",
      "[18201 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 7. Calcular el acumulado de ventas (running total) por cliente.\n",
    "# -------------------------------\n",
    "df7 = pd.read_sql(\"\"\"\n",
    "WITH t1 AS (\n",
    "    SELECT DATETRUNC(month, v.fecha_venta) AS periodo,\n",
    "           v.id_cliente, c.nombre,\n",
    "           SUM(v.precio_unitario * v.cantidad) AS total\n",
    "    FROM ventas v INNER JOIN clientes c ON v.id_cliente = c.id_cliente\n",
    "    GROUP BY DATETRUNC(month, v.fecha_venta), v.id_cliente, c.nombre\n",
    ")\n",
    "SELECT *, SUM(total) OVER (PARTITION BY id_cliente ORDER BY periodo) AS acumulado\n",
    "FROM t1;\n",
    "\"\"\", engine)\n",
    "print(df7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b70daad-fa3b-495a-8442-f75c650a4f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id_cliente  id_venta fecha_venta fecha_venta_anterior  prom_tiempo\n",
      "0               1     18172  2023-01-10                 None          NaN\n",
      "1               1       188  2023-01-12           2023-01-10          2.0\n",
      "2               1     15312  2023-02-05           2023-01-12         13.0\n",
      "3               1     14137  2023-03-07           2023-02-05         18.0\n",
      "4               1     29564  2023-03-10           2023-03-07         14.0\n",
      "...           ...       ...         ...                  ...          ...\n",
      "32762         800      9407  2025-04-21           2025-02-25         24.0\n",
      "32763         800     26127  2025-05-13           2025-04-21         24.0\n",
      "32764         800     11852  2025-06-06           2025-05-13         24.0\n",
      "32765         800     27342  2025-06-26           2025-06-06         24.0\n",
      "32766         800      6991  2025-07-25           2025-06-26         24.0\n",
      "\n",
      "[32767 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 8. Determinar el tiempo promedio entre compras por cliente.\n",
    "# -------------------------------\n",
    "df8 = pd.read_sql(\"\"\"\n",
    "WITH t1 AS (\n",
    "    SELECT id_cliente, id_venta, fecha_venta,\n",
    "           LAG(fecha_venta) OVER (PARTITION BY id_cliente ORDER BY fecha_venta) AS fecha_venta_anterior\n",
    "    FROM ventas v\n",
    ")\n",
    "SELECT id_cliente, id_venta, fecha_venta, fecha_venta_anterior,\n",
    "       AVG(DATEDIFF(day, fecha_venta_anterior, fecha_venta)) OVER (PARTITION BY id_cliente ORDER BY fecha_venta) AS prom_tiempo\n",
    "FROM t1;\n",
    "\"\"\", engine)\n",
    "print(df8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27d2b859-7160-41c1-91d6-90ea24a93cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id_producto nombre_producto   rentabilidad\n",
      "0           23     Producto 23  139390.936077\n",
      "1           29     Producto 29  555878.270134\n",
      "2           15     Producto 15 -498935.103289\n",
      "3            9      Producto 9   62334.715202\n",
      "4            3      Producto 3 -234497.495781\n",
      "5           32     Producto 32  265664.530558\n",
      "6           26     Producto 26  394417.102495\n",
      "7           12     Producto 12 -116307.105106\n",
      "8           35     Producto 35 -494823.397219\n",
      "9            6      Producto 6   69626.572454\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 9. Identificar los 10 productos con mayor rentabilidad (ingresos - costo).\n",
    "# -------------------------------\n",
    "df9 = pd.read_sql(\"\"\"\n",
    "SELECT TOP 10 p.id_producto, p.nombre_producto,\n",
    "       SUM(v.precio_unitario * cantidad) - SUM(p.precio_lista * v.cantidad) AS rentabilidad\n",
    "FROM productos p INNER JOIN ventas v ON p.id_producto = v.id_producto\n",
    "GROUP BY p.id_producto, p.nombre_producto;\n",
    "\"\"\", engine)\n",
    "print(df9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa123fd9-5122-45ad-949e-77b64fea27ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   canal     periodo  dist_porcentual\n",
      "0    APP  2023-02-01         0.000000\n",
      "1    APP  2023-01-01         3.333333\n",
      "2    APP  2024-02-01         6.666667\n",
      "3    APP  2025-04-01        10.000000\n",
      "4    APP  2024-09-01        13.333333\n",
      "..   ...         ...              ...\n",
      "88   WEB  2024-08-01        86.666667\n",
      "89   WEB  2023-03-01        90.000000\n",
      "90   WEB  2023-07-01        93.333333\n",
      "91   WEB  2024-09-01        96.666667\n",
      "92   WEB  2024-12-01       100.000000\n",
      "\n",
      "[93 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 10. Calcular la distribución porcentual de ventas por canal y mes.\n",
    "# -------------------------------\n",
    "df10 = pd.read_sql(\"\"\"\n",
    "SELECT canal, DATETRUNC(month, fecha_venta) AS periodo,\n",
    "       PERCENT_RANK() OVER (PARTITION BY canal ORDER BY SUM(precio_unitario * cantidad)) * 100 AS dist_porcentual\n",
    "FROM ventas\n",
    "GROUP BY canal, DATETRUNC(month, fecha_venta);\n",
    "\"\"\", engine)\n",
    "print(df10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5f17205-9539-4d6a-9df3-e25ba857a10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    anio  trimestre         total  trimestre_anterior  indicador\n",
      "0   2023          1  2.378343e+06                 NaN  no_aplica\n",
      "1   2023          2  2.627290e+06        2.378343e+06     subida\n",
      "2   2023          3  2.423345e+06        2.627290e+06     bajada\n",
      "3   2023          4  2.453568e+06        2.423345e+06     subida\n",
      "4   2024          1  2.486619e+06        2.453568e+06     subida\n",
      "5   2024          2  2.418425e+06        2.486619e+06     bajada\n",
      "6   2024          3  2.520541e+06        2.418425e+06     subida\n",
      "7   2024          4  2.547033e+06        2.520541e+06     subida\n",
      "8   2025          1  2.485396e+06        2.547033e+06     bajada\n",
      "9   2025          2  2.356042e+06        2.485396e+06     bajada\n",
      "10  2025          3  8.230328e+05        2.356042e+06     bajada\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 11. Mostrar la tendencia de ventas trimestral (subida/bajada).\n",
    "# -------------------------------\n",
    "df11 = pd.read_sql(\"\"\"\n",
    "WITH t1 AS (\n",
    "    SELECT DATEPART(year, fecha_venta) AS anio,\n",
    "           DATEPART(quarter, fecha_venta) AS trimestre,\n",
    "           SUM(precio_unitario * cantidad) AS total,\n",
    "           LAG(SUM(precio_unitario * cantidad)) OVER (ORDER BY DATEPART(year, fecha_venta), DATEPART(quarter, fecha_venta)) AS trimestre_anterior\n",
    "    FROM ventas\n",
    "    GROUP BY DATEPART(year, fecha_venta), DATEPART(quarter, fecha_venta)\n",
    ")\n",
    "SELECT *, CASE WHEN total < trimestre_anterior THEN 'bajada'\n",
    "               WHEN total > trimestre_anterior THEN 'subida'\n",
    "               WHEN total = trimestre_anterior THEN 'sin_variacion'\n",
    "               ELSE 'no_aplica' END AS indicador\n",
    "FROM t1;\n",
    "\"\"\", engine)\n",
    "print(df11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd584b08-cc3d-451d-b012-d80f42bde885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id_vendedor       nombre   percentil\n",
      "0           29  Empleado 29   91.836735\n",
      "1           42  Empleado 42   93.877551\n",
      "2           47  Empleado 47   95.918367\n",
      "3           41  Empleado 41   97.959184\n",
      "4           21  Empleado 21  100.000000\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 12. Encontrar empleados cuyo salario está por encima del percentil 90.\n",
    "# -------------------------------\n",
    "df12 = pd.read_sql(\"\"\"\n",
    "WITH t1 AS (\n",
    "    SELECT id_vendedor, nombre,\n",
    "           PERCENT_RANK() OVER (ORDER BY salario) * 100 AS percentil\n",
    "    FROM empleados\n",
    ")\n",
    "SELECT * FROM t1 WHERE percentil >= 90;\n",
    "\"\"\", engine)\n",
    "print(df12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d31fe0c8-5b47-4fa0-ae2c-c71633acfd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     region  id_producto  cantidad_1 region  id_producto  cantidad_2\n",
      "0    Centro            9      241582  Norte            9      238497\n",
      "1    Centro           12      210589  Norte           12      209440\n",
      "2    Centro           15      203250  Norte           15      205820\n",
      "3    Centro           18      205086  Norte           18      213332\n",
      "4    Centro           38      266012  Norte           38      263993\n",
      "..      ...          ...         ...    ...          ...         ...\n",
      "115   Norte           11      213213    Sur           11      215204\n",
      "116   Norte           14      214894    Sur           14      225780\n",
      "117   Norte           17      219501    Sur           17      226486\n",
      "118   Norte           20      237437    Sur           20      240219\n",
      "119   Norte           40      234360    Sur           40      229425\n",
      "\n",
      "[120 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 16. Identificar productos con ventas duplicadas en diferentes regiones.\n",
    "# -------------------------------\n",
    "df16 = pd.read_sql(\"\"\"\n",
    "SELECT v1.region, v1.id_producto, SUM(v1.cantidad) AS cantidad_1,\n",
    "       v2.region, v2.id_producto, SUM(v2.cantidad) AS cantidad_2\n",
    "FROM ventas v1 INNER JOIN ventas v2\n",
    "  ON v1.region < v2.region AND v1.id_producto = v2.id_producto\n",
    "GROUP BY v1.region, v2.region, v1.id_producto, v2.id_producto;\n",
    "\"\"\", engine)\n",
    "print(df16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c61d1477-590c-4e2c-978d-1323f52d35d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ponderado\n",
      "0  259.356422\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 17. Calcular el promedio de ventas ponderado por cantidad.\n",
    "# -------------------------------\n",
    "df17 = pd.read_sql(\"SELECT SUM(precio_unitario * cantidad) / SUM(cantidad) AS ponderado FROM ventas;\", engine)\n",
    "print(df17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6ef8bcc-4836-4c12-972b-188324ce925c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id_vendedor       nombre   ranking\n",
      "0           34  Empleado 34  0.959184\n",
      "1           38  Empleado 38  0.979592\n",
      "2           30  Empleado 30  1.000000\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 18. Mostrar el top 5% de vendedores según facturación total.\n",
    "# -------------------------------\n",
    "df18 = pd.read_sql(\"\"\"\n",
    "WITH t1 AS (\n",
    "    SELECT v.id_vendedor, e.nombre,\n",
    "           PERCENT_RANK() OVER (ORDER BY SUM(precio_unitario * cantidad)) AS ranking\n",
    "    FROM ventas v INNER JOIN empleados e ON v.id_vendedor = e.id_vendedor\n",
    "    GROUP BY v.id_vendedor, e.nombre\n",
    ")\n",
    "SELECT * FROM t1 WHERE ranking >= 0.95;\n",
    "\"\"\", engine)\n",
    "print(df18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac8d0eae-d8ed-46ce-9782-b55ffc2cdd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id_cliente  total_cliente  promedio_global  desvia_global\n",
      "0          501   15934.619980      31899.54316    6365.970048\n",
      "1          779   18696.580090      31899.54316    6365.970048\n",
      "2          507   14399.370144      31899.54316    6365.970048\n",
      "3          338   17566.680185      31899.54316    6365.970048\n",
      "4          146   46654.009836      31899.54316    6365.970048\n",
      "5          573   45303.130314      31899.54316    6365.970048\n",
      "6          510   17937.200020      31899.54316    6365.970048\n",
      "7          702   48907.379944      31899.54316    6365.970048\n",
      "8          112   46614.010073      31899.54316    6365.970048\n",
      "9           64   17152.939903      31899.54316    6365.970048\n",
      "10         350   18952.909988      31899.54316    6365.970048\n",
      "11         685   51230.529732      31899.54316    6365.970048\n",
      "12         124   17318.490023      31899.54316    6365.970048\n",
      "13         794   45216.379730      31899.54316    6365.970048\n",
      "14         508   45661.790176      31899.54316    6365.970048\n",
      "15         339   46210.340075      31899.54316    6365.970048\n",
      "16         411   18604.729916      31899.54316    6365.970048\n",
      "17         420   44857.619913      31899.54316    6365.970048\n",
      "18          13   47066.769842      31899.54316    6365.970048\n",
      "19         202   44816.180237      31899.54316    6365.970048\n",
      "20         606   44862.369961      31899.54316    6365.970048\n",
      "21          16   49086.589737      31899.54316    6365.970048\n",
      "22          45   18040.239956      31899.54316    6365.970048\n",
      "23         686   16467.619961      31899.54316    6365.970048\n",
      "24         641   18473.780003      31899.54316    6365.970048\n",
      "25          94   17458.289967      31899.54316    6365.970048\n",
      "26          77   45872.399769      31899.54316    6365.970048\n",
      "27         558   45776.210285      31899.54316    6365.970048\n",
      "28         111   44871.960073      31899.54316    6365.970048\n",
      "29         214   45935.540230      31899.54316    6365.970048\n",
      "30          20   16370.059978      31899.54316    6365.970048\n",
      "31         343   49909.009983      31899.54316    6365.970048\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 19. Detectar clientes cuya facturación está fuera del rango normal del global de compras.\n",
    "# -------------------------------\n",
    "df19 = pd.read_sql(\"\"\"\n",
    "WITH t1 AS (\n",
    "    SELECT id_cliente,\n",
    "           SUM(precio_unitario * cantidad) AS total_cliente,\n",
    "           AVG(SUM(precio_unitario * cantidad)) OVER () AS promedio_global,\n",
    "           STDEV(SUM(precio_unitario * cantidad)) OVER () AS desvia_global\n",
    "    FROM ventas\n",
    "    GROUP BY id_cliente\n",
    ")\n",
    "SELECT * FROM t1\n",
    "WHERE total_cliente > promedio_global + 2 * desvia_global\n",
    "   OR total_cliente < promedio_global - 2 * desvia_global;\n",
    "\"\"\", engine)\n",
    "print(df19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "266948c8-2085-4a85-9694-e6cdb8c25315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   region  promedio_días_region\n",
      "0  Centro                     0\n",
      "1   Norte                     0\n",
      "2     Sur                     0\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 20. Calcular la cantidad de días promedio entre pedido por región.\n",
    "# -------------------------------\n",
    "df20 = pd.read_sql(\"\"\"\n",
    "WITH t1 AS (\n",
    "    SELECT region, fecha_venta,\n",
    "           LEAD(fecha_venta,1) OVER (PARTITION BY region ORDER BY fecha_venta) AS fecha_siguiente,\n",
    "           DATEDIFF(day, fecha_venta, LEAD(fecha_venta,1) OVER (PARTITION BY region ORDER BY fecha_venta)) AS dif_dias\n",
    "    FROM ventas\n",
    ")\n",
    "SELECT region, AVG(dif_dias) AS promedio_días_region\n",
    "FROM t1 GROUP BY region;\n",
    "\"\"\", engine)\n",
    "print(df20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7101d8a-2908-4639-9146-38a98b28de58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  categoria periodo_anio  ventas_anuales  ventas_anuales_anterior  \\\n",
      "0  Juguetes   2024-01-01    3.309160e+06             3.118825e+06   \n",
      "1     Hogar   2024-01-01    2.790910e+06             2.692195e+06   \n",
      "2      Ropa   2024-01-01    2.236764e+06             2.303553e+06   \n",
      "\n",
      "       variacion  \n",
      "0  190334.928848  \n",
      "1   98714.728830  \n",
      "2  -66788.892008  \n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 21. Obtener las 3 categorías con mayor aumento de ventas interanual.\n",
    "# -------------------------------\n",
    "df21 = pd.read_sql(\"\"\"\n",
    "WITH t1 AS (\n",
    "    SELECT p.categoria, DATETRUNC(year, v.fecha_venta) AS periodo_anio,\n",
    "           SUM(v.precio_unitario * v.cantidad) AS ventas_anuales,\n",
    "           LAG(SUM(v.precio_unitario * v.cantidad), 1) OVER (PARTITION BY p.categoria ORDER BY DATETRUNC(year, v.fecha_venta)) AS ventas_anuales_anterior,\n",
    "           SUM(v.precio_unitario * v.cantidad) - LAG(SUM(v.precio_unitario * v.cantidad), 1) OVER (PARTITION BY p.categoria ORDER BY DATETRUNC(year, v.fecha_venta)) AS variacion\n",
    "    FROM ventas v INNER JOIN productos p ON v.id_producto = p.id_producto\n",
    "    GROUP BY p.categoria, DATETRUNC(year, v.fecha_venta)\n",
    "),\n",
    "t2 AS (\n",
    "    SELECT categoria, MAX(variacion) AS v_max\n",
    "    FROM t1 GROUP BY categoria\n",
    ")\n",
    "SELECT TOP(3) t1.categoria, t1.periodo_anio, t1.ventas_anuales, t1.ventas_anuales_anterior, t1.variacion\n",
    "FROM t1 INNER JOIN t2 ON t1.categoria = t2.categoria AND t1.variacion = t2.v_max\n",
    "ORDER BY t1.variacion DESC;\n",
    "\"\"\", engine)\n",
    "print(df21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b98bb4d-dd75-47c8-93b4-9554b3975a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            venta  incremento_ventas  porcentaje_clientes\n",
      "0    14399.370144           0.000000                0.125\n",
      "1    15934.619980           0.125156                0.250\n",
      "2    16370.059978           0.250313                0.375\n",
      "3    16467.619961           0.375469                0.500\n",
      "4    17152.939903           0.500626                0.625\n",
      "..            ...                ...                  ...\n",
      "635  37281.579880          79.474343               79.500\n",
      "636  37307.349796          79.599499               79.625\n",
      "637  37349.689877          79.724656               79.750\n",
      "638  37503.730263          79.849812               79.875\n",
      "639  37551.050377          79.974969               80.000\n",
      "\n",
      "[640 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 22. Analizar qué porcentaje de clientes generan el 80% de los ingresos (regla 80/20).\n",
    "# -------------------------------\n",
    "df22 = pd.read_sql(\"\"\"\n",
    "WITH t1 AS (\n",
    "    SELECT id_cliente,\n",
    "           SUM(precio_unitario * cantidad) AS venta,\n",
    "           PERCENT_RANK() OVER (ORDER BY SUM(precio_unitario * cantidad)) * 100.00 AS incremento_ventas\n",
    "    FROM ventas\n",
    "    GROUP BY id_cliente\n",
    "),\n",
    "t2 AS (\n",
    "    SELECT *, COUNT(id_cliente) OVER (ORDER BY incremento_ventas) * 1.0 /\n",
    "                 COUNT(id_cliente) OVER () * 100 AS porcentaje_clientes\n",
    "    FROM t1\n",
    ")\n",
    "SELECT venta, incremento_ventas, porcentaje_clientes\n",
    "FROM t2 WHERE porcentaje_clientes <= 80;\n",
    "\"\"\", engine)\n",
    "print(df22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "617e60a6-4c6c-4673-a6e2-aca92a838902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       periodo  id_producto  menor_incremento\n",
      "0   2025-07-01           10     -12707.819885\n",
      "1   2025-03-01            1     -17182.909870\n",
      "2   2024-11-01           16     -12993.420073\n",
      "3   2023-05-01            5     -18613.139904\n",
      "4   2023-07-01           39     -14225.390133\n",
      "5   2024-02-01           20     -13927.870094\n",
      "6   2025-02-01           36     -18694.459984\n",
      "7   2024-07-01            1     -16899.530045\n",
      "8   2024-03-01           34     -17034.350101\n",
      "9   2023-04-01           21     -28051.040070\n",
      "10  2023-03-01           35     -15427.680149\n",
      "11  2025-05-01            2     -12156.060213\n",
      "12  2023-10-01            7     -17004.749786\n",
      "13  2023-09-01           32     -13043.430149\n",
      "14  2024-04-01           29     -18628.290371\n",
      "15  2025-06-01            6     -12057.069946\n",
      "16  2024-05-01            1     -11316.439753\n",
      "17  2025-04-01           13     -13847.850142\n",
      "18  2025-01-01           37     -16065.519987\n",
      "19  2023-11-01           31     -13701.599977\n",
      "20  2023-06-01            3     -18957.490267\n",
      "21  2024-01-01           15     -15281.119848\n",
      "22  2023-08-01           10     -19259.720116\n",
      "23  2024-10-01           23     -15306.330093\n",
      "24  2024-06-01            6     -14954.459999\n",
      "25  2023-02-01           30     -12565.359848\n",
      "26  2023-12-01           38     -16973.449516\n",
      "27  2024-08-01            5     -14028.730001\n",
      "28  2024-12-01           17     -16875.280018\n",
      "29  2024-09-01           40     -13776.739834\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 23. Encontrar el producto con mayor caída de ventas mes a mes.\n",
    "# -------------------------------\n",
    "df23 = pd.read_sql(\"\"\"\n",
    "WITH t1 AS (\n",
    "    SELECT DATETRUNC(month, fecha_venta) AS periodo, id_producto,\n",
    "           SUM(precio_unitario * cantidad) AS venta_mensual,\n",
    "           LAG(SUM(precio_unitario * cantidad),1) OVER (PARTITION BY id_producto ORDER BY DATETRUNC(month, fecha_venta)) AS venta_mes_anterior\n",
    "    FROM ventas\n",
    "    GROUP BY DATETRUNC(month, fecha_venta), id_producto\n",
    "),\n",
    "t2 AS (\n",
    "    SELECT periodo, MIN(venta_mes_anterior - venta_mensual) OVER (PARTITION BY periodo) AS menor_incremento\n",
    "    FROM t1\n",
    ")\n",
    "SELECT a.periodo, a.id_producto, b.menor_incremento\n",
    "FROM t1 a INNER JOIN t2 b ON a.periodo = b.periodo\n",
    "  AND a.venta_mes_anterior - a.venta_mensual = b.menor_incremento\n",
    "  AND a.venta_mes_anterior IS NOT NULL\n",
    "GROUP BY a.periodo, a.id_producto, b.menor_incremento;\n",
    "\"\"\", engine)\n",
    "print(df23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33ce7f29-e0cd-4e7a-9be8-10a3cbf2dd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       categoria     periodo          item1  promedio_de_importe_de_cada_mes  \\\n",
      "0    Electronica  2023-01-01  155024.609795                       779.018140   \n",
      "1    Electronica  2023-02-01  138642.420197                       761.771540   \n",
      "2    Electronica  2023-03-01  143643.180031                       886.686296   \n",
      "3    Electronica  2023-04-01  165020.380075                       789.571197   \n",
      "4    Electronica  2023-05-01  171689.610134                       825.430818   \n",
      "..           ...         ...            ...                              ...   \n",
      "119         Ropa  2025-03-01  187035.229898                       763.409102   \n",
      "120         Ropa  2025-04-01  171729.060129                       753.197632   \n",
      "121         Ropa  2025-05-01  191949.119867                       830.948571   \n",
      "122         Ropa  2025-06-01  171754.100172                       795.157871   \n",
      "123         Ropa  2025-07-01  195374.699959                       807.333471   \n",
      "\n",
      "     promedio_mensual  \n",
      "0       155024.609795  \n",
      "1       146833.514996  \n",
      "2       145770.070007  \n",
      "3       150582.647524  \n",
      "4       154804.040046  \n",
      "..                ...  \n",
      "119     193857.111495  \n",
      "120     192028.748272  \n",
      "121     190716.468236  \n",
      "122     184834.016635  \n",
      "123     187434.123320  \n",
      "\n",
      "[124 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 24. Calcular la media móvil de 6 meses por categoría de producto.\n",
    "# -------------------------------\n",
    "df24 = pd.read_sql(\"\"\"\n",
    "SELECT p.categoria, DATETRUNC(month, v.fecha_venta) AS periodo,\n",
    "       SUM(v.precio_unitario * v.cantidad) AS item1,\n",
    "       AVG(v.precio_unitario * v.cantidad) AS promedio_de_importe_de_cada_mes,\n",
    "       AVG(SUM(v.precio_unitario * v.cantidad)) OVER (PARTITION BY p.categoria ORDER BY DATETRUNC(month, v.fecha_venta) ROWS BETWEEN 5 PRECEDING AND CURRENT ROW) AS promedio_mensual\n",
    "FROM ventas v INNER JOIN productos p ON v.id_producto = p.id_producto\n",
    "GROUP BY p.categoria, DATETRUNC(month, v.fecha_venta);\n",
    "\"\"\", engine)\n",
    "print(df24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d112a12-4268-4da0-af51-a0b87eef7988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id_cliente  venta_promedio_cliente  ranking\n",
      "0           696             1077.421187        1\n",
      "1           436             1058.055386        2\n",
      "2           508             1037.767959        3\n",
      "3           687             1032.201624        4\n",
      "4           545             1029.016872        5\n",
      "..          ...                     ...      ...\n",
      "795         507              553.821929      796\n",
      "796         523              542.724143      797\n",
      "797         222              537.116317      798\n",
      "798         501              531.153999      799\n",
      "799         686              514.613124      800\n",
      "\n",
      "[800 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 25. Crear un ranking de clientes con base en su ticket promedio.\n",
    "# -------------------------------\n",
    "df25 = pd.read_sql(\"\"\"\n",
    "SELECT id_cliente,\n",
    "       AVG(precio_unitario * cantidad) AS venta_promedio_cliente,\n",
    "       DENSE_RANK() OVER (ORDER BY AVG(precio_unitario * cantidad) DESC) AS ranking\n",
    "FROM ventas\n",
    "GROUP BY id_cliente;\n",
    "\"\"\", engine)\n",
    "print(df25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52d3a984-23cd-4f8d-a885-39ea7131c55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id_vendedor  promedio_venta_vendedor  desv_por_vendedor\n",
      "0            23               760.129088         589.773116\n",
      "1            46               795.559911         603.135172\n",
      "2            29               769.719589         594.653452\n",
      "3            15               789.537651         597.274796\n",
      "4             9               785.134680         621.341561\n",
      "5             3               755.285491         555.781734\n",
      "6            32               794.376103         602.998834\n",
      "7            26               785.834747         607.306618\n",
      "8            12               767.950226         604.264536\n",
      "9            35               770.455071         583.886721\n",
      "10            6               776.429317         555.097890\n",
      "11           43               780.986307         559.427874\n",
      "12           49               793.870642         615.515763\n",
      "13           27               795.532139         596.030240\n",
      "14           21               801.639205         604.362998\n",
      "15           38               813.636720         611.895082\n",
      "16           44               771.435245         565.740443\n",
      "17            7               787.731972         585.807945\n",
      "18           50               774.991060         580.725464\n",
      "19            1               787.302314         568.816971\n",
      "20           24               766.505845         580.384556\n",
      "21           47               780.454044         597.052201\n",
      "22           30               805.689165         586.789420\n",
      "23           18               747.204544         594.547971\n",
      "24           10               800.168138         579.484103\n",
      "25           41               749.196361         604.895028\n",
      "26            4               736.598425         570.348830\n",
      "27           19               749.034069         590.615797\n",
      "28           25               806.982480         594.105323\n",
      "29           36               784.513805         581.432644\n",
      "30           13               755.417355         580.729588\n",
      "31           42               775.336189         597.104080\n",
      "32            5               779.387023         586.853666\n",
      "33           22               789.568839         586.085945\n",
      "34           39               797.983857         585.420326\n",
      "35           33               770.542563         607.791010\n",
      "36           16               776.896234         572.716644\n",
      "37           45               785.159782         599.727042\n",
      "38            2               761.161015         565.106933\n",
      "39           48               787.748464         589.488566\n",
      "40           17               773.222014         581.458196\n",
      "41           31               758.247294         570.821459\n",
      "42           34               827.160903         588.076630\n",
      "43           40               779.991275         578.864504\n",
      "44           11               789.658204         583.502943\n",
      "45           20               786.694290         588.653070\n",
      "46           28               763.846357         574.162163\n",
      "47           14               753.716551         603.745216\n",
      "48           37               734.589806         591.871293\n",
      "49            8               800.039196         604.939444\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 26. Calcular el promedio y desviación estándar de ventas por vendedor.\n",
    "# -------------------------------\n",
    "df26 = pd.read_sql(\"\"\"\n",
    "SELECT id_vendedor,\n",
    "       AVG(precio_unitario * cantidad) AS promedio_venta_vendedor,\n",
    "       STDEV(precio_unitario * cantidad) AS desv_por_vendedor\n",
    "FROM ventas\n",
    "GROUP BY id_vendedor;\n",
    "\"\"\", engine)\n",
    "print(df26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "572f534f-80ea-470a-8971-71368f10c97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id_venta, id_cliente, id_producto, fecha_venta, cantidad, precio_unitario, canal, region, estado_entrega, Cant_identicos]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 27. Detectar duplicados en registros de transacciones.\n",
    "# -------------------------------\n",
    "df27 = pd.read_sql(\"\"\"\n",
    "WITH t1 AS (\n",
    "    SELECT id_venta, id_cliente, id_producto, fecha_venta, cantidad, precio_unitario, canal, region, estado_entrega,\n",
    "           COUNT(*) AS Cant_identicos\n",
    "    FROM ventas\n",
    "    GROUP BY id_venta, id_cliente, id_producto, fecha_venta, cantidad, precio_unitario, canal, region, estado_entrega\n",
    ")\n",
    "SELECT * FROM t1 WHERE Cant_identicos > 1;\n",
    "\"\"\", engine)\n",
    "print(df27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3413f9af-b467-4d19-b4d3-2d770cb50326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    periodo_registro periodo_venta NuevoAntiguo  cantidad\n",
      "0         2022-03-01    2024-12-01        nuevo        10\n",
      "1         2021-06-01    2024-12-01        nuevo        37\n",
      "2         2021-05-01    2024-07-01        nuevo        40\n",
      "3         2020-05-01    2024-04-01        nuevo        42\n",
      "4         2021-08-01    2025-05-01        nuevo        34\n",
      "..               ...           ...          ...       ...\n",
      "832       2020-04-01    2025-02-01        nuevo        39\n",
      "833       2022-02-01    2024-10-01        nuevo        37\n",
      "834       2021-05-01    2024-01-01        nuevo        41\n",
      "835       2021-12-01    2023-05-01        nuevo        32\n",
      "836       2020-02-01    2023-03-01        nuevo        42\n",
      "\n",
      "[837 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 28. Analizar clientes nuevos vs recurrentes en un periodo determinado.\n",
    "# -------------------------------\n",
    "df28 = pd.read_sql(\"\"\"\n",
    "WITH t1 AS (\n",
    "    SELECT v.id_cliente, c.fecha_registro, v.fecha_venta,\n",
    "           CASE WHEN c.fecha_registro <= v.fecha_venta THEN 'nuevo' ELSE 'antiguo' END AS NuevoAntiguo\n",
    "    FROM ventas v INNER JOIN clientes c ON v.id_cliente = c.id_cliente\n",
    ")\n",
    "SELECT DATETRUNC(month, fecha_registro) AS periodo_registro,\n",
    "       DATETRUNC(month, fecha_venta) AS periodo_venta,\n",
    "       NuevoAntiguo,\n",
    "       COUNT(NuevoAntiguo) AS cantidad\n",
    "FROM t1\n",
    "GROUP BY DATETRUNC(month, fecha_registro), DATETRUNC(month, fecha_venta), NuevoAntiguo;\n",
    "\"\"\", engine)\n",
    "print(df28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f87453f-2440-47d6-810e-315137a7bc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id_cliente     periodo  venta_mensual  venta_mes_anterior\n",
      "0           142  2023-01-01    2439.079918                 NaN\n",
      "1           142  2023-04-01     210.080002         2439.079918\n",
      "2           142  2023-05-01     472.989990          210.080002\n",
      "3           142  2023-06-01     628.700006          472.989990\n",
      "4           142  2023-07-01    3128.570072          628.700006\n",
      "..          ...         ...            ...                 ...\n",
      "227         702  2024-12-01    3901.360077         1369.709930\n",
      "228         702  2025-01-01     733.019989         3901.360077\n",
      "229         702  2025-03-01    1269.159988          733.019989\n",
      "230         702  2025-04-01    1770.860016         1269.159988\n",
      "231         702  2025-05-01    2887.030029         1770.860016\n",
      "\n",
      "[232 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 29. Calcular el crecimiento relativo del top 10 de clientes.\n",
    "# -------------------------------\n",
    "df29 = pd.read_sql(\"\"\"\n",
    "WITH t1 AS (\n",
    "    SELECT TOP(10) id_cliente, SUM(precio_unitario * cantidad) AS venta_cliente\n",
    "    FROM ventas\n",
    "    GROUP BY id_cliente\n",
    ")\n",
    "SELECT a.id_cliente,\n",
    "       DATETRUNC(month, v.fecha_venta) AS periodo,\n",
    "       SUM(v.precio_unitario * v.cantidad) AS venta_mensual,\n",
    "       LAG(SUM(precio_unitario * cantidad),1) OVER (PARTITION BY a.id_cliente ORDER BY DATETRUNC(month, v.fecha_venta)) AS venta_mes_anterior\n",
    "FROM t1 a INNER JOIN ventas v ON a.id_cliente = v.id_cliente\n",
    "GROUP BY a.id_cliente, DATETRUNC(month, v.fecha_venta);\n",
    "\"\"\", engine)\n",
    "print(df29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3af14cf-3f2d-4715-9137-0fb6522b00a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    periodo    ventas_mes  incremento_mensual  ranking_de_ventas_mensuales  \\\n",
      "0         5  2.559070e+06        1.237904e+07                            1   \n",
      "1         3  2.542465e+06        7.350359e+06                            2   \n",
      "2         7  2.529583e+06        1.728170e+07                            3   \n",
      "3         1  2.473469e+06        2.473469e+06                            4   \n",
      "4         4  2.469610e+06        9.819969e+06                            5   \n",
      "5         6  2.373077e+06        1.475212e+07                            6   \n",
      "6         2  2.334426e+06        4.807894e+06                            7   \n",
      "7        12  1.714663e+06        2.551963e+07                            8   \n",
      "8        10  1.670676e+06        2.218971e+07                            9   \n",
      "9         8  1.660317e+06        1.894202e+07                           10   \n",
      "10       11  1.615261e+06        2.380497e+07                           11   \n",
      "11        9  1.577018e+06        2.051903e+07                           12   \n",
      "\n",
      "     total_venta  porcentaje  \n",
      "0   2.551963e+07   10.027847  \n",
      "1   2.551963e+07    9.962779  \n",
      "2   2.551963e+07    9.912303  \n",
      "3   2.551963e+07    9.692414  \n",
      "4   2.551963e+07    9.677294  \n",
      "5   2.551963e+07    9.299025  \n",
      "6   2.551963e+07    9.147567  \n",
      "7   2.551963e+07    6.718994  \n",
      "8   2.551963e+07    6.546630  \n",
      "9   2.551963e+07    6.506037  \n",
      "10  2.551963e+07    6.329485  \n",
      "11  2.551963e+07    6.179625  \n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 30. Crear un resumen mensual con ventas acumuladas, ranking y porcentaje sobre total.\n",
    "# -------------------------------\n",
    "df30 = pd.read_sql(\"\"\"\n",
    "SELECT DATEPART(month, fecha_venta) AS periodo,\n",
    "       SUM(precio_unitario * cantidad) AS ventas_mes,\n",
    "       SUM(SUM(precio_unitario * cantidad)) OVER (ORDER BY DATEPART(month, fecha_venta)) AS incremento_mensual,\n",
    "       DENSE_RANK() OVER (ORDER BY SUM(precio_unitario * cantidad) DESC) AS ranking_de_ventas_mensuales,\n",
    "       SUM(SUM(precio_unitario * cantidad)) OVER () AS total_venta,\n",
    "       SUM(precio_unitario * cantidad) * 1.0 / SUM(SUM(precio_unitario * cantidad)) OVER () * 100 AS porcentaje\n",
    "FROM ventas\n",
    "GROUP BY DATEPART(month, fecha_venta);\n",
    "\"\"\", engine)\n",
    "print(df30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77d6fca-4602-4288-8577-b8c6cbbdfbad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
